# RAG 文本切片策略与优化

本文系统梳理 RAG（检索增强生成）中的“文本切片（Chunking）”策略，并结合业界实践给出优化与拓展建议。切片质量直接影响检索命中与答案准确性，是 RAG 的核心基础设施之一。

## 为什么要切片
- 上下文窗口限制：大模型一次只能处理有限长度的输入，长文档必须拆分。
- 精准检索：细粒度切片便于索引与定位，提高 Recall 与相关性。
- 代价与效率：合理切片可降低嵌入与检索成本，提升吞吐。

## 五种高级切片策略（概览）
以下策略来自对实践经验的总结，并结合对“改进固定长度、语义切片、LLM 语义切片、层次切片、滑动窗口切片”等方法的系统分析。

### 1. 改进的固定长度切片（边界感知）
- 核心思想：预设目标长度，在接近长度阈值处选择自然语言边界（句号、问号、换行）切分，避免“句中断裂”。
- 典型流程：
  1) 先按段落或双换行进行粗分；
  2) 对超长段落按句子分隔符（. ? !）二次分割；
  3) 在接近目标长度处优先选择句边界作为切点。
- 优点：高效、实现简单，明显优于朴素固定长度。
- 局限：对复杂语义单元（表格、代码块、跨句论证）保持不佳。
- 适用：通用文本，作为“默认安全策略”的良好折中。

### 2. 语义切片（Embedding 相似度驱动）
- 核心思想：依据相邻句段的嵌入相似度或主题转折信号决定边界，保证语义完整。
- 典型做法：计算句向量，按“相似度骤降点”“主题转折点”进行分段；或基于段落/标题的语义聚类。
- 优点：对论述结构、主题连续性保持更好，常提升检索精度。
- 局限：需要额外计算，阈值与算法超参需调优；对嘈杂文本敏感。
- 适用：高精度问答、长论述类文档（白皮书、手册）。

### 3. LLM 语义切片（模型辅助分割）
- 核心思想：用大模型按“主题/任务/意图”对文本进行智能分段，产出带标签的块。
- 典型做法：设计提示词，要求模型输出标题、摘要、要点与边界；可结合结构化格式（JSON/Markdown）。
- 优点：对复杂文档（混排、跨段论证、规范条款）效果佳，块的可读性与元数据质量高。
- 局限：成本较高，受提示与模型稳定性影响；需防止过分主观分割。
- 适用：规章制度、设计文档、技术方案、规范条款。

### 4. 层次切片（多粒度结构）
- 核心思想：多层粒度（章节→段落→句子/小节）组织，检索时“粗召回、细重排”。
- 典型做法：先生成大块（章节/小节），再在块内生成细粒度子块；索引与检索同时维护层次关系。
- 优点：兼顾覆盖与精度，支持层次化检索与聚合回答；适配长文档。
- 局限：实现与索引维护复杂，评估需考虑跨层影响。
- 适用：书籍、手册、长报告、法律文本。

### 5. 滑动窗口切片（高重叠上下文）
- 核心思想：固定长度窗口并设置重叠（overlap），保证跨块信息连续。
- 典型做法：窗口长度 N，步长 S（S < N），重叠 O = N - S；对长段落或代码尤为有效。
- 优点：缓解“边界丢失”，提升实体、跨句线索的覆盖；实现简单。
- 局限：索引规模膨胀、重复内容增多；重排器重要性更高。
- 适用：代码、公式、规范条款、术语密集文本。

## 进一步的补充与拓展策略
### 6. 结构感知切片（Layout/Markup/Ast-aware）
- Markdown/HTML：按标题层级（H1-H3）或 DOM 节点切分，保留层级与锚点。
- PDF/Layout：利用目录、页眉页脚、版面块（如表格、图注）作为边界；结合版面解析（LayoutLMv3 等）。
- 代码 AST：基于语法树（tree-sitter 等）按函数/类/模块切分，保留 import/调用关系元数据。
- 表格数据：按表头、行块、单元格分区，并补充语义化描述（列含义、度量单位）。

### 7. 动态自适应切片
- 基于密度/困惑度：遇到信息密集段落适当缩短块，稀疏段落适当拉长，控制“信息每块单位”均衡。
- 主题转折检测：借助 TextTiling、段落相似度序列的变化率自动决定边界。
- 模型上下文自适应：根据目标模型上下文窗口与检索 Top-K 设定，动态调整 chunk_size 与 overlap。

### 8. 跨块关系与知识联结
- 块间引用：记录块间依赖（引用、调用、同主题）作为图结构，用于跨块检索与答案拼接。
- 元数据标签：主题、实体、术语、时效、版本、来源；支持细粒度过滤与重排。
- 块摘要与锚点：每块生成短摘要与关键锚点词，便于多查询扩展（multi-query）。

### 9. 多模态与混合内容
- 图片/图表：为图片生成描述（Caption/OCR），将图注与相关段落合并切片。
- 公式/代码：保证公式与解释在同一块；代码示例与讲解配对切分。
- 多语言文档：按语言段落切分，维持语言一致性，避免跨语言混拼。

## 参数与实践建议
- chunk_size：中文一般以字数或 token 计，常见范围 300–800 token；代码可更短（函数/类级别）。
- overlap：一般 10–25% 起步；代码与规范类可提高至 30–50%。
- 边界优先级：标题 > 段落 > 句子 > 标点；尽量避免句中断裂与跨主题拼接。
- 规范化：清洗无意义空白、统一编码与分隔符；保留结构标记（列表、标题、代码块）。
- 索引设计：同时维护文本块索引与层次/关系索引（Graph/Parent-Child），支持跨块检索。
- 混合检索：BM25/FT 与向量检索融合，多查询扩展 + 重排器（Cross-Encoder/LLM Rerank）。

## 评估与对比（离线与在线）
- 离线指标：Recall@K、MRR、nDCG、Precision@K；任务型可用答案重建率、覆盖率。
- 集合构建：针对 FAQ/真实问题集标注“理想证据片段”，用于切片方案 A/B 对比。
- 在线监控：首条命中文本块是否含关键信息、答案引用率、人工审查通过率。
- 消融实验：逐步调整 chunk_size/overlap/边界策略，评估对检索与生成的影响。

## 实施参考（流程）

1) 文本预处理与结构抽取（清洗、语言检测、版面解析）
2) 选择切片策略（可组合）：固定长度+边界感知、语义/LLM 辅助、层次组织、滑窗增强  
3) 生成块元数据（标题、摘要、实体、主题标签、来源、层次/关系）  
4) 嵌入与索引（向量 + 关键词/全文检索 + 关系图）  
5) 检索与重排（多查询扩展、混合检索、交叉编码器/LLM 重排）  
6) 答案生成与引用（跨块拼接、引用原文、避免幻觉）  
7) 评估与迭代（离线指标 + 在线监控 + 消融实验）

## 资料与参考

- 构建 AI 智能体的 RAG 切片策略综述与实践经验，涵盖改进固定长度、语义切片、LLM 语义切片、层次切片、滑动窗口等方法
- 更多业界实践：结构感知、AST 切片、混合检索与重排、离线指标与消融评估、动态自适应策略
- 示例链接：阿里云开发者社区《优化 RAG 检索精度：五种高级切片策略》 https://developer.aliyun.com/article/1688285


# 已实现策略

- 改进固定长度（边界感知）： agentlz/services/chunk_embeddings_service.py:339
- 语义切片（相邻句嵌入相似度）： agentlz/services/chunk_embeddings_service.py:416
- LLM 语义切片（占位实现）： agentlz/services/chunk_embeddings_service.py:490
- 层次切片（章节→段落→句子）： agentlz/services/chunk_embeddings_service.py:535
- 滑动窗口切片（高重叠）： agentlz/services/chunk_embeddings_service.py:570
- 结构感知切片（标题/代码/列表/表格）： agentlz/services/chunk_embeddings_service.py:602
- 动态自适应切片（密度/困惑度启发式）： agentlz/services/chunk_embeddings_service.py:655
- 跨块关系与联结（链接/引用就近合并，占位）： agentlz/services/chunk_embeddings_service.py:694
